# ML System Design Document: Harry Potter RAG

## 1. Зачем идем в разработку продукта?

Цель проекта — создать интерактивную систему, позволяющую пользователям задавать вопросы по сюжету, персонажам и деталям книг серии «Гарри Поттер» и получать точные ответы с прямыми цитатами из текста и указанием источника (название книги и номер главы). Это решает проблему трудоёмкого поиска информации в объёмных текстах и обеспечивает прозрачность: пользователь видит, откуда взят ответ. Система включает backend (FastAPI) и frontend (React), а генерация ответов выполняется с помощью Mistral AI API (бесплатная версия)

## 2. Бизнес-требования и ограничения

*   **Функциональные требования:**
    *   Система принимает текстовый вопрос от пользователя через веб-интерфейс (React).
    *   Backend (FastAPI) обрабатывает запрос, ищет релевантные фрагменты в книгах с сохранением метаданных (`book`, `chapter`).
    *   Система формирует промпт и отправляет его в **Mistral AI API**.
    *   Полученный ответ структурируется и возвращается с **прямой цитатой** и **ссылкой на источник** (например: *«Гарри Поттер и Орден Феникса, глава 37»*).
    *   Ответ отображается на фронтенде.

*   **Нефункциональные требования:**
    *   Ответы должны быть основаны **только на предоставленном контексте** (ретривнутых фрагментах).
    *   Время отклика — до **10–15 секунд** (с учётом задержек Mistral API).
    *   MVP должен быть реализован за **2 месяца**.
    *   Качество будет оценено вручную на **30–50 вопросах**; целевой порог — ≥80% ответов с корректной цитатой и источником.

*   **Ограничения:**
    *   Используются только тексты книг (7 томов), полученные из открытых источников (например, [Flibusta](https://flibusta.site)) **в образовательных целях**.
    *   Зависимость от **Mistral AI API**: требуется интернет и API-ключ.
    *   Бесплатный тариф Mistral может иметь **ограничения по количеству запросов/токенов в минуту** — система должна обрабатывать ошибки (429 Too Many Requests).
    *   Поддержка только одного языка (язык исходного текста: русский или английский).
    *   На этапе MVP не предполагается поддержка истории диалога или сложной логики.

## 3. Что входит в скоуп проекта/итерации, что не входит

*   **Входит:**
    *   Предобработка текстов: парсинг, разбиение по главам, извлечение метаданных (`book`, `chapter`).
    *   Векторизация чанков с привязкой к метаданным.
    *   Локальное векторное хранилище (FAISS или Chroma).
    *   RAG-пайплайн: ретривер + формирование промпта + вызов **Mistral API**.
    *   Backend на **FastAPI** с эндпоинтом `/ask`, включающим обработку ошибок API.
    *   Frontend на **React** с полем ввода и отображением: ответ, цитата, источник.
    *   Использование **бесплатной версии Mistral API** (модель, например, `mistral-small-latest` или `open-mistral-7b`).

*   **Не входит:**
    *   Локальный запуск LLM (всё генерация — через Mistral API).
    *   Кэширование ответов или запросов (в MVP).
    *   Мультиязычная поддержка.
    *   История чата, авторизация, админка.
    *   Поддержка других серий книг или внешних источников (вики, фильмы).

## 4. Предпосылки решения

Mistral AI предоставляет бесплатный доступ к мощным open-weight моделям с низкой задержкой и хорошим качеством генерации. Это позволяет сосредоточиться на RAG-логике, а не на развертывании LLM локально. Наличие структурированного текста с главами даёт возможность точного цитирования. Архитектура FastAPI + React обеспечивает чёткое разделение backend и frontend.

## 5. Постановка задачи

Реализовать систему, которая по вопросу пользователя (например, *«Почему Добби освободился от семьи Малфоев?»*) возвращает структурированный ответ:

> **Ответ**: Добби освободился, потому что Люциус Малфой случайно дал ему носок — предмет одежды, что по законам домовиков означает освобождение.  
> **Цитата**: *«Ты не должен был давать мне носок!» — воскликнул Люциус Малфой, глядя на Добби с ненавистью.*  
> **Источник**: *«Гарри Поттер и Тайная комната», глава 18*

**Основная метрика успеха**:  
— ≥80% ответов на тестовом наборе из 30–50 вопросов содержат релевантную цитату и корректно указанную книгу и главу.

### 5.1. Ручная оценка
- **Объём**: 30–50 вопросов, охватывающих факты, сюжет, мотивации персонажей.
- **Трудозатраты**: ~2 минуты на вопрос → **1–1.5 часа** на одного оценщика.
- **Процедура**: два участника независимо оценивают; согласованность фиксируется.

### 5.2. Автоматизированная оценка (опционально)
- `hit_rate@5` для ретривера.
- Логирование ошибок Mistral API (429, 5xx) для анализа надёжности.

> Финальное решение о качестве — по результатам ручной оценки.

### 3. Этапы решения задачи

#### Этап 1. Подготовка данных

*   **Описание данных/сущностей:**
    *   **Источник:** Тексты семи книг серии «Гарри Поттер» на русском языке в формате `.txt`.
    *   **Сущности:** Главы книг. Каждая глава разбивается на чанки для поиска.
    *   **Проблемы и риски:**
        1.  **Качество текста:** Артефакты форматирования (`[\u2028\u2029\xA0]`) могут мешать парсингу. Обрабатывается в `data_preparation.py`.
        2.  **Объем данных:** 197 глав (~1.2 млн слов) - достаточно для задачи.
        3.  **Разметка:** Отсутствует. Система полагается на точность контекста.
    *   **Процесс генерации данных:**
        *   **Поступление:** `.txt` файлы в папке `/data`.
        *   **Формат:** Строго "Глава X".
        *   **Процесс:** При старте системы вызывается `load_all_books()` → `parse_book_to_chapters()` → создает объекты `Document` с метаданными `{book, chapter}`.
    *   **Необходимость дополнительных данных:** Не требуется.
    *   **Конфиденциальная информация:** Нет.
*   **Необходимый результат этапа:** Список документов по главам для семантического чанкинга.

#### **Этап 2. Подготовка прогнозных моделей**

*   **ML-метрики:** **Accuracy** — доля правильно отвеченных вопросов. Обоснование: цель — фактическая точность.
*   **Схема валидации:** Hold-out на `valid_questions.json`. **Ручная проверка** (`is_correct`) обязательна из-за семантической эквивалентности.
*   **Бейзлайн:**
    1.  **Предобработка запроса:** Расширение ключевыми словами через LLM.
    2.  **Поиск:** Гибридный (Chroma + BM25) с RRF.
    3.  **Чанкинг:** `SemanticChunker` с порогом 600 слов.
    4.  **Генерация:** Mistral AI с жестким промптом ("Только по контексту").
*   **Стратегии развития:**
    1.  Настройка `similarity_threshold`, весов RRF.
    2.  Улучшение промпта (few-shot).
    3.  Авто-подбор гиперпараметров.
*   **Анализ модели:** По `results.json`. Ошибки типа "Не знаю" анализируются на предмет проблем с поиском или генерацией.
*   **Риски:**
    *   **Hallucinations:** Снижение — строгий промпт и ручная проверка.
    *   **Неточный поиск:** Снижение — гибридный поиск.
    *   **Зависимость от API:** Снижение — повторные попытки.
*   **Необходимый результат:** Файл `results.json` с точностью ≥80%.

#### **Этапы, специфические для задачи RAG**

*   **Этап 3. Управление контекстом и генерация ответов**
    *   **Описание:** Критический этап для качества.
    *   **Техника:**
        1.  **Извлечение контекста:** Топ-15 чанков объединяются.
        2.  **Форматирование:** Явное указание `[ИСТОЧНИК: ...]`.
        3.  **Генерация:** Температура 0.0 для детерминированности.
    *   **Риски:**
        *   Длинный ответ - снижение: `temperature=0.0`.
        *   Нет ответа в контексте - снижение: инструкция "Не знаю".
    *   **Необходимый результат:** Ответ либо с цитатой, либо "Не знаю".

## 6. Блок-схема решения

[Пользователь вводит вопрос в React-интерфейсе]
                     ↓
       [POST /ask → FastAPI backend]
                     ↓
[Retriever: поиск топ-K чанков + извлечение metadata (book, chapter)]
                     ↑
[Векторное хранилище ← Тексты книг, размеченные по главам]
                     ↓
[Формирование промпта для Mistral API:
 "Ответь ТОЛЬКО на основе приведённых ниже отрывков.
  Обязательно включи ПРЯМУЮ ЦИТАТУ из текста и укажи НАЗВАНИЕ КНИГИ и НОМЕР ГЛАВЫ.
  Не выдумывай информацию."]
                     ↓
        [Запрос к Mistral AI API (через HTTP)]
                     ↓
    [Обработка ответа: извлечение/валидация цитаты и источника]
                     ↓
 [FastAPI возвращает JSON: {answer: str, quote: str, source: str}]
                     ↓
   [React отображает ответ, цитату и источник пользователю]